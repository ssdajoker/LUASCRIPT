
name: LUASCRIPT Comprehensive Audit Pipeline

on:
  push:
    branches: [ main, audit-framework, phase* ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run nightly audit at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      audit_round:
        description: 'Audit Round (1-4)'
        required: true
        default: '1'
        type: choice
        options:
        - '1'
        - '2'
        - '3'
        - '4'

env:
  AUDIT_ROUND: ${{ github.event.inputs.audit_round || '1' }}
  NODE_VERSION: '18'
  LUA_VERSION: '5.1'

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      audit-round: ${{ steps.setup.outputs.audit-round }}
      timestamp: ${{ steps.setup.outputs.timestamp }}
    steps:
    - name: Setup Audit Environment
      id: setup
      run: |
        echo "audit-round=${{ env.AUDIT_ROUND }}" >> $GITHUB_OUTPUT
        echo "timestamp=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_OUTPUT
        echo "🎯 Starting Audit Round ${{ env.AUDIT_ROUND }}"

  static-analysis:
    runs-on: ubuntu-latest
    needs: setup
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Lua Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y lua5.1 luajit luarocks
        sudo luarocks install luacheck
        sudo luarocks install luacov
    
    - name: Run Static Analysis
      run: |
        mkdir -p reports/round${{ needs.setup.outputs.audit-round }}/static
        echo "🔍 Running Static Analysis - Round ${{ needs.setup.outputs.audit-round }}"
        luacheck src/ test/ --no-color > reports/round${{ needs.setup.outputs.audit-round }}/static/luacheck.txt || true
        echo "📊 Static Analysis Complete"
    
    - name: Upload Static Analysis Results
      uses: actions/upload-artifact@v4
      with:
        name: static-analysis-round${{ needs.setup.outputs.audit-round }}
        path: reports/round${{ needs.setup.outputs.audit-round }}/static/

  unit-tests:
    runs-on: ubuntu-latest
    needs: setup
    strategy:
      matrix:
        test-suite: [transpiler, arrow-functions, memory-management, phase3, phase4]
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
    
    - name: Setup Lua Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y lua5.1 luajit luarocks
        sudo luarocks install busted
        sudo luarocks install luacov
    
    - name: Run Unit Tests - ${{ matrix.test-suite }}
      run: |
        mkdir -p reports/round${{ needs.setup.outputs.audit-round }}/unit
        echo "🧪 Running ${{ matrix.test-suite }} tests - Round ${{ needs.setup.outputs.audit-round }}"
        
        case "${{ matrix.test-suite }}" in
          "transpiler")
            node test/test_transpiler.js > reports/round${{ needs.setup.outputs.audit-round }}/unit/transpiler.txt 2>&1
            ;;
          "arrow-functions")
            node tests/test_arrow_functions.js > reports/round${{ needs.setup.outputs.audit-round }}/unit/arrow-functions.txt 2>&1
            ;;
          "memory-management")
            node tests/test_memory_management.js > reports/round${{ needs.setup.outputs.audit-round }}/unit/memory-management.txt 2>&1
            ;;
          "phase3")
            luajit test/test_phase3_implementation.lua > reports/round${{ needs.setup.outputs.audit-round }}/unit/phase3.txt 2>&1
            ;;
          "phase4")
            luajit test/test_phase4_implementation.lua > reports/round${{ needs.setup.outputs.audit-round }}/unit/phase4.txt 2>&1
            ;;
        esac
    
    - name: Upload Unit Test Results
      uses: actions/upload-artifact@v4
      with:
        name: unit-tests-${{ matrix.test-suite }}-round${{ needs.setup.outputs.audit-round }}
        path: reports/round${{ needs.setup.outputs.audit-round }}/unit/

  integration-tests:
    runs-on: ubuntu-latest
    needs: [setup, unit-tests]
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y lua5.1 luajit luarocks nodejs npm
        sudo luarocks install busted
        sudo luarocks install luacov
    
    - name: Run Integration Tests
      run: |
        mkdir -p reports/round${{ needs.setup.outputs.audit-round }}/integration
        echo "🔗 Running Integration Tests - Round ${{ needs.setup.outputs.audit-round }}"
        
        # Run full test suite
        npm test > reports/round${{ needs.setup.outputs.audit-round }}/integration/full-suite.txt 2>&1
        
        # Test cross-phase integration
        echo "Testing Phase 1 → Phase 2 integration" >> reports/round${{ needs.setup.outputs.audit-round }}/integration/cross-phase.txt
        node -e "
          const transpiler = require('./src/transpiler.js');
          const fs = require('fs');
          const testCode = 'let x = \"Hello\" + \" World\"; console.log(x);';
          const luaCode = transpiler.transpile(testCode);
          fs.writeFileSync('/tmp/test_integration.lua', luaCode);
          console.log('Transpilation successful');
        " >> reports/round${{ needs.setup.outputs.audit-round }}/integration/cross-phase.txt 2>&1
        
        luajit /tmp/test_integration.lua >> reports/round${{ needs.setup.outputs.audit-round }}/integration/cross-phase.txt 2>&1
    
    - name: Upload Integration Test Results
      uses: actions/upload-artifact@v4
      with:
        name: integration-tests-round${{ needs.setup.outputs.audit-round }}
        path: reports/round${{ needs.setup.outputs.audit-round }}/integration/

  performance-tests:
    runs-on: ubuntu-latest
    needs: [setup, unit-tests]
    if: ${{ needs.setup.outputs.audit-round >= '2' }}
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y lua5.1 luajit luarocks nodejs npm time
        sudo luarocks install busted
    
    - name: Run Performance Tests
      run: |
        mkdir -p reports/round${{ needs.setup.outputs.audit-round }}/performance
        echo "⚡ Running Performance Tests - Round ${{ needs.setup.outputs.audit-round }}"
        
        # Transpilation performance
        echo "=== Transpilation Performance ===" > reports/round${{ needs.setup.outputs.audit-round }}/performance/transpilation.txt
        for i in {1..10}; do
          /usr/bin/time -f "Run $i: %e seconds, %M KB memory" node src/transpiler.js examples/phase1b_demo.js /tmp/perf_test_$i.lua 2>> reports/round${{ needs.setup.outputs.audit-round }}/performance/transpilation.txt
        done
        
        # Runtime performance
        echo "=== Runtime Performance ===" > reports/round${{ needs.setup.outputs.audit-round }}/performance/runtime.txt
        for i in {1..10}; do
          /usr/bin/time -f "Run $i: %e seconds, %M KB memory" luajit /tmp/perf_test_$i.lua 2>> reports/round${{ needs.setup.outputs.audit-round }}/performance/runtime.txt
        done
    
    - name: Upload Performance Test Results
      uses: actions/upload-artifact@v4
      with:
        name: performance-tests-round${{ needs.setup.outputs.audit-round }}
        path: reports/round${{ needs.setup.outputs.audit-round }}/performance/

  stress-tests:
    runs-on: ubuntu-latest
    needs: [setup, integration-tests]
    if: ${{ needs.setup.outputs.audit-round >= '3' }}
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y lua5.1 luajit luarocks nodejs npm
        sudo luarocks install busted
    
    - name: Run Stress Tests
      run: |
        mkdir -p reports/round${{ needs.setup.outputs.audit-round }}/stress
        echo "💪 Running Stress Tests - Round ${{ needs.setup.outputs.audit-round }}"
        
        # Memory stress test
        echo "=== Memory Stress Test ===" > reports/round${{ needs.setup.outputs.audit-round }}/stress/memory.txt
        node -e "
          const transpiler = require('./src/transpiler.js');
          console.log('Starting memory stress test...');
          for (let i = 0; i < 1000; i++) {
            const code = 'let x' + i + ' = \"test\" + \"string\" + i;';
            transpiler.transpile(code);
            if (i % 100 === 0) console.log('Processed', i, 'iterations');
          }
          console.log('Memory stress test completed');
        " >> reports/round${{ needs.setup.outputs.audit-round }}/stress/memory.txt 2>&1
        
        # Concurrent execution stress test
        echo "=== Concurrency Stress Test ===" > reports/round${{ needs.setup.outputs.audit-round }}/stress/concurrency.txt
        for i in {1..5}; do
          (luajit test/test_phase3_implementation.lua > /tmp/concurrent_$i.log 2>&1 &)
        done
        wait
        echo "All concurrent tests completed" >> reports/round${{ needs.setup.outputs.audit-round }}/stress/concurrency.txt
    
    - name: Upload Stress Test Results
      uses: actions/upload-artifact@v4
      with:
        name: stress-tests-round${{ needs.setup.outputs.audit-round }}
        path: reports/round${{ needs.setup.outputs.audit-round }}/stress/

  coverage-analysis:
    runs-on: ubuntu-latest
    needs: [setup, unit-tests, integration-tests]
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y lua5.1 luajit luarocks nodejs npm
        sudo luarocks install luacov
        sudo luarocks install busted
    
    - name: Generate Coverage Report
      run: |
        mkdir -p reports/round${{ needs.setup.outputs.audit-round }}/coverage
        echo "📊 Generating Coverage Report - Round ${{ needs.setup.outputs.audit-round }}"
        
        # Run tests with coverage
        luacov -c .luacov test/test_phase3_implementation.lua > reports/round${{ needs.setup.outputs.audit-round }}/coverage/phase3_coverage.txt 2>&1 || true
        luacov -c .luacov test/test_phase4_implementation.lua > reports/round${{ needs.setup.outputs.audit-round }}/coverage/phase4_coverage.txt 2>&1 || true
        
        # Generate coverage summary
        if [ -f luacov.stats.out ]; then
          luacov > reports/round${{ needs.setup.outputs.audit-round }}/coverage/summary.txt 2>&1
        fi
    
    - name: Upload Coverage Results
      uses: actions/upload-artifact@v4
      with:
        name: coverage-analysis-round${{ needs.setup.outputs.audit-round }}
        path: reports/round${{ needs.setup.outputs.audit-round }}/coverage/

  audit-report:
    runs-on: ubuntu-latest
    needs: [setup, static-analysis, unit-tests, integration-tests, performance-tests, stress-tests, coverage-analysis]
    if: always()
    steps:
    - uses: actions/checkout@v4
    
    - name: Download All Artifacts
      uses: actions/download-artifact@v4
      with:
        path: artifacts/
    
    - name: Generate Audit Report
      run: |
        mkdir -p reports/round${{ needs.setup.outputs.audit-round }}/final
        echo "📋 Generating Final Audit Report - Round ${{ needs.setup.outputs.audit-round }}"
        
        cat > reports/round${{ needs.setup.outputs.audit-round }}/final/audit_report.md << 'EOF'
        # LUASCRIPT AUDIT REPORT - ROUND ${{ needs.setup.outputs.audit-round }}
        
        **Audit Date**: $(date)
        **Audit Round**: ${{ needs.setup.outputs.audit-round }}
        **Commit**: ${{ github.sha }}
        
        ## EXECUTIVE SUMMARY
        
        This report summarizes the results of Audit Round ${{ needs.setup.outputs.audit-round }} for the LUASCRIPT project.
        
        ## TEST RESULTS SUMMARY
        
        ### Static Analysis
        - Luacheck warnings: $(find artifacts/ -name "luacheck.txt" -exec wc -l {} \; | awk '{sum+=$1} END {print sum}' || echo "N/A")
        
        ### Unit Tests
        - Transpiler Tests: $(grep -c "✅\|PASSED" artifacts/*/transpiler.txt 2>/dev/null || echo "N/A")
        - Phase 3 Tests: $(grep -c "WORKING\|COMPLETE" artifacts/*/phase3.txt 2>/dev/null || echo "N/A")
        - Phase 4 Tests: $(grep -c "WORKING\|COMPLETE" artifacts/*/phase4.txt 2>/dev/null || echo "N/A")
        
        ### Integration Tests
        - Cross-phase integration: $(grep -c "successful" artifacts/*/cross-phase.txt 2>/dev/null || echo "N/A")
        
        ## QUALITY GATES STATUS
        
        ### Gate 1: Basic Functionality
        - [ ] All existing tests pass
        - [ ] No critical static analysis issues
        - [ ] Basic transpilation works
        - [ ] Runtime library functional
        
        ### Gate 2: Feature Completeness
        - [ ] All Phase 1-4 features implemented
        - [ ] Edge cases handled properly
        - [ ] Error messages are clear
        - [ ] Performance meets benchmarks
        
        ### Gate 3: System Integration
        - [ ] All phases work together
        - [ ] Memory management stable
        - [ ] No memory leaks detected
        - [ ] Stress tests pass
        
        ### Gate 4: Production Readiness
        - [ ] Documentation complete
        - [ ] All tests automated
        - [ ] CI/CD pipeline functional
        - [ ] Boss final approval
        
        ## RECOMMENDATIONS
        
        Based on the audit results, the following actions are recommended:
        
        1. Address static analysis warnings
        2. Improve test coverage
        3. Enhance performance benchmarks
        4. Complete documentation gaps
        
        ## NEXT STEPS
        
        - Proceed to Round ${{ needs.setup.outputs.audit-round + 1 }} if quality gates are met
        - Address identified issues before next round
        - Update audit checklist based on findings
        
        ---
        
        **Audit Team**: 21 Legendary Developers
        **Audit Framework**: Comprehensive Multi-Round Validation
        **Payment Status**: Pending Boss Approval
        EOF
    
    - name: Upload Final Audit Report
      uses: actions/upload-artifact@v4
      with:
        name: final-audit-report-round${{ needs.setup.outputs.audit-round }}
        path: reports/round${{ needs.setup.outputs.audit-round }}/final/
    
    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const reportPath = 'reports/round${{ needs.setup.outputs.audit-round }}/final/audit_report.md';
          if (fs.existsSync(reportPath)) {
            const report = fs.readFileSync(reportPath, 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## 🎯 LUASCRIPT Audit Report - Round ${{ needs.setup.outputs.audit-round }}\n\n${report}`
            });
          }
